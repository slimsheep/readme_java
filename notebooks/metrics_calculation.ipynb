{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5777f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582468ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readme = pd.read_csv('../java_nonpersonal_readme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "782eaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readme = df_readme[(df_readme.stars != 0) & (df_readme.forked_from == 0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213d946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "      <th>url</th>\n",
       "      <th>forked_from</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>readme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Glomes</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/SnowblindFatal/Gl...</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>Glomes is (was?) a project made by J. Saarela ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147</td>\n",
       "      <td>ActionBarSherlock</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/JakeWharton/Actio...</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>8330</td>\n",
       "      <td># DEPRECATED\\n\\nActionBarSherlock is deprecate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190</td>\n",
       "      <td>SimianArmy</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/Netflix/SimianArmy</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>6714</td>\n",
       "      <td>[![NetflixOSS Lifecycle](https://img.shields.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252</td>\n",
       "      <td>rstudio</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/rstudio/rstudio</td>\n",
       "      <td>0</td>\n",
       "      <td>1904</td>\n",
       "      <td>2731</td>\n",
       "      <td>RStudio\\n=====================================...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313</td>\n",
       "      <td>IGV</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/igvteam/igv</td>\n",
       "      <td>0</td>\n",
       "      <td>2076</td>\n",
       "      <td>133</td>\n",
       "      <td># igv\\n[![Build Status](https://travis-ci.org/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142466</th>\n",
       "      <td>137562943</td>\n",
       "      <td>Notes</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/DaveAAA/Notes</td>\n",
       "      <td>0</td>\n",
       "      <td>41194524</td>\n",
       "      <td>2</td>\n",
       "      <td># Notes.\\nNotes is a mobile application for ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142467</th>\n",
       "      <td>137574913</td>\n",
       "      <td>SocketChat</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/DemS98/SocketChat</td>\n",
       "      <td>0</td>\n",
       "      <td>46417714</td>\n",
       "      <td>1</td>\n",
       "      <td># SocketChat\\nSocketChat consists in two appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142468</th>\n",
       "      <td>137584454</td>\n",
       "      <td>SebUzduotis</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/MartinCepulionis/...</td>\n",
       "      <td>0</td>\n",
       "      <td>51559454</td>\n",
       "      <td>1</td>\n",
       "      <td># SebUzduotis\\n\\nAfter you input two integers(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142469</th>\n",
       "      <td>137596645</td>\n",
       "      <td>adoptopenjdk-plugin</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/jenkinsci/adoptop...</td>\n",
       "      <td>0</td>\n",
       "      <td>2206</td>\n",
       "      <td>1</td>\n",
       "      <td>Jenkins AdoptOpenJDK installer Plugin\\n=======...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142470</th>\n",
       "      <td>137602271</td>\n",
       "      <td>classmate-radar</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://api.github.com/repos/fuzious/classmate...</td>\n",
       "      <td>0</td>\n",
       "      <td>46417962</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;h1 style=\"text-align:center\"&gt;Classmate Radar&lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142471 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                 name language  \\\n",
       "0              33               Glomes     Java   \n",
       "1             147    ActionBarSherlock     Java   \n",
       "2             190           SimianArmy     Java   \n",
       "3             252              rstudio     Java   \n",
       "4             313                  IGV     Java   \n",
       "...           ...                  ...      ...   \n",
       "142466  137562943                Notes     Java   \n",
       "142467  137574913           SocketChat     Java   \n",
       "142468  137584454          SebUzduotis     Java   \n",
       "142469  137596645  adoptopenjdk-plugin     Java   \n",
       "142470  137602271      classmate-radar     Java   \n",
       "\n",
       "                                                      url  forked_from  \\\n",
       "0       https://api.github.com/repos/SnowblindFatal/Gl...            0   \n",
       "1       https://api.github.com/repos/JakeWharton/Actio...            0   \n",
       "2         https://api.github.com/repos/Netflix/SimianArmy            0   \n",
       "3            https://api.github.com/repos/rstudio/rstudio            0   \n",
       "4                https://api.github.com/repos/igvteam/igv            0   \n",
       "...                                                   ...          ...   \n",
       "142466         https://api.github.com/repos/DaveAAA/Notes            0   \n",
       "142467     https://api.github.com/repos/DemS98/SocketChat            0   \n",
       "142468  https://api.github.com/repos/MartinCepulionis/...            0   \n",
       "142469  https://api.github.com/repos/jenkinsci/adoptop...            0   \n",
       "142470  https://api.github.com/repos/fuzious/classmate...            0   \n",
       "\n",
       "        owner_id  stars                                             readme  \n",
       "0            140      4  Glomes is (was?) a project made by J. Saarela ...  \n",
       "1            896   8330  # DEPRECATED\\n\\nActionBarSherlock is deprecate...  \n",
       "2           1600   6714  [![NetflixOSS Lifecycle](https://img.shields.i...  \n",
       "3           1904   2731  RStudio\\n=====================================...  \n",
       "4           2076    133  # igv\\n[![Build Status](https://travis-ci.org/...  \n",
       "...          ...    ...                                                ...  \n",
       "142466  41194524      2  # Notes.\\nNotes is a mobile application for ta...  \n",
       "142467  46417714      1  # SocketChat\\nSocketChat consists in two appli...  \n",
       "142468  51559454      1  # SebUzduotis\\n\\nAfter you input two integers(...  \n",
       "142469      2206      1  Jenkins AdoptOpenJDK installer Plugin\\n=======...  \n",
       "142470  46417962      2  <h1 style=\"text-align:center\">Classmate Radar<...  \n",
       "\n",
       "[142471 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c4eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36597af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_metrics_calculated = pd.read_csv('../metrics_nonezero_nonefork_v7.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc0944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c16a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bdcb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# from markdown import markdown\n",
    "# from markdown2 import markdown\n",
    "from mistune import markdown\n",
    "import spacy\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import csv\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c60d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_NLP = spacy.load(\"en_core_web_sm\")\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a2e572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_contain_kw_direct(lst, kw):\n",
    "    for item in lst:\n",
    "        if kw in item:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def list_kw_index(lst, kw):\n",
    "    for i, item in enumerate(lst):\n",
    "        for token in item.split():\n",
    "            clean_token = token.replace('-', '').replace('?', '').replace('.', '').replace(':', '')\n",
    "            if stemmer.stem(clean_token).startswith(stemmer.stem(kw)):\n",
    "                #         print(token, kw)\n",
    "                return i\n",
    "\n",
    "    #   kw = ''.join(remove_special_chars(kw))\n",
    "    #   if not kw:\n",
    "    #     return -1\n",
    "\n",
    "    #   for i, item in enumerate(lst):\n",
    "    #     resonstructed_name = item.replace('-','').replace('_','').replace(' ','').replace('.','').replace(':','')\n",
    "    #     if kw in resonstructed_name or resonstructed_name in kw:\n",
    "    #       if not resonstructed_name:\n",
    "    #         continue\n",
    "    #       return i\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "def header_contain_project_name(lst, kw):\n",
    "    kw = ''.join(remove_special_chars(kw))\n",
    "\n",
    "    if not kw:\n",
    "        return 0\n",
    "\n",
    "    for item in lst:\n",
    "        resonstructed_name = item.replace('-', '').replace('_', '').replace(' ', '').replace('.', '').replace(':', '')\n",
    "        #     print(resonstructed_name)\n",
    "\n",
    "        if not resonstructed_name:\n",
    "            continue\n",
    "\n",
    "        if kw in resonstructed_name or resonstructed_name in kw:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def list_contains_exact(lst, kw):\n",
    "    for item in lst:\n",
    "        for token in item.split():\n",
    "            if token == kw:\n",
    "                return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def list_contains(lst, kw):\n",
    "    for item in lst:\n",
    "        for token in item.split():\n",
    "            clean_token = token.replace('-', '').replace('?', '').replace('.', '').replace(':', '')\n",
    "            if stemmer.stem(clean_token).startswith(stemmer.stem(kw)):\n",
    "                #       if token.startswith(kw):\n",
    "                return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def preprocess_readme(readme_md):\n",
    "    html = md2html(readme_md)\n",
    "\n",
    "    rm_clean = convert_markdown(html)\n",
    "\n",
    "    nocode = rm_clean\n",
    "\n",
    "    for code in find_all_codes(readme_md):\n",
    "        rm_clean = rm_clean.replace(code[1], '')\n",
    "\n",
    "    return nocode, rm_clean\n",
    "\n",
    "\n",
    "def find_all_badges(md):\n",
    "    t_list = BeautifulSoup(markdown(md)).find_all('img')\n",
    "\n",
    "    # print(t_list)\n",
    "\n",
    "    rv = []\n",
    "\n",
    "    for img in t_list:\n",
    "        c = str(img).lower()\n",
    "        if 'badge' in c:\n",
    "            rv.append(img)\n",
    "        elif 'svg' in c:\n",
    "            if 'hack23' in c or 'travis' in c or 'coveralls' in c or 'shields.io' in c or 'davideas':\n",
    "                rv.append(img)\n",
    "\n",
    "    return rv\n",
    "\n",
    "\n",
    "def find_all_urls(md):\n",
    "    t_list = BeautifulSoup(markdown(md)).find_all('a')\n",
    "    return t_list\n",
    "\n",
    "\n",
    "def find_all_images(md):\n",
    "    t_list = BeautifulSoup(markdown(md)).find_all('img')\n",
    "    return t_list\n",
    "\n",
    "\n",
    "def find_all_blocks(md):\n",
    "    html = BeautifulSoup(markdown(md))\n",
    "    t_list = html.find_all(re.compile('^h[1-6]$'))\n",
    "    headers = [(x.name, x.text.lower()) for x in t_list]\n",
    "\n",
    "    blocks = []\n",
    "\n",
    "    i = 0\n",
    "    moving = ''\n",
    "\n",
    "    for child in html.recursiveChildGenerator():\n",
    "        if child.name:\n",
    "            #       print(child.name, child.text)\n",
    "            #       if child.text:\n",
    "            if i == len(headers):\n",
    "                moving += str(child)\n",
    "            elif child.name == headers[i][0] and child.text.lower() == headers[i][1]:\n",
    "                blocks.append(moving)\n",
    "                i += 1\n",
    "                moving = ''\n",
    "            else:\n",
    "                moving += str(child) + '\\n'\n",
    "    blocks.append(moving)\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def find_all_codes(md):\n",
    "    t_list = BeautifulSoup(markdown(md)).find_all('code')\n",
    "    return [(x.name, x.text) for x in t_list]\n",
    "\n",
    "\n",
    "def find_all_headers(md):\n",
    "    t_list = BeautifulSoup(markdown(md)).find_all(re.compile('^h[1-6]$'))\n",
    "    return [(x.name, x.text.lower()) for x in t_list]\n",
    "\n",
    "\n",
    "def remove_special_chars(readme):\n",
    "    return list(map(lambda x: re.sub(\"[^a-zA-Z ]\", \"\", x), readme))\n",
    "\n",
    "\n",
    "def filter_readme(readme, lemmatize=True, lowercase=True, remove_stopwords=True,\n",
    "                  remove_punctuation=True, remove_digits=True, remove_space=True,\n",
    "                  remove_like_num=True, remove_short=True,\n",
    "                  remove_contains_num=True, remove_nonenglish=True,\n",
    "                  remove_hyperlink=True):\n",
    "    doc = SPACY_NLP(readme)  # Create Spacy Document\n",
    "    isEnglishReadme = True\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        # Exclude tokens from stopwords list\n",
    "        if remove_stopwords and token.is_stop:\n",
    "            continue\n",
    "        # Exclude tokens from punctuations list\n",
    "        elif remove_punctuation and token.is_punct:\n",
    "            continue\n",
    "        # Exclude tokens that are digits\n",
    "        elif remove_digits and token.is_digit:\n",
    "            continue\n",
    "        # Exclude whitespace characters\n",
    "        elif remove_space and token.is_space:\n",
    "            continue\n",
    "        # Exclude tokens that are similar to numbers (e.g., \"ten\")\n",
    "        elif remove_like_num and token.like_num:\n",
    "            continue\n",
    "        # Exclude tokens that are shorter than 3 characters\n",
    "        elif remove_short and len(token) < 3:\n",
    "            continue\n",
    "        # Exclude tokens that contain a number\n",
    "        elif remove_contains_num and not re.search(\"[0-9]\", token.text) is None:\n",
    "            continue\n",
    "        elif remove_nonenglish and not isEnglish(token.text):\n",
    "            isEnglishReadme = False\n",
    "            continue\n",
    "        elif remove_hyperlink and not re.search(r'((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)',\n",
    "                                                token.text) is None:\n",
    "            continue\n",
    "        else:\n",
    "            if lemmatize:  # Return lemma\n",
    "                filtered_token = token.lemma_\n",
    "            else:\n",
    "                filtered_token = token.text\n",
    "\n",
    "            if lowercase:  # Return lowercased token\n",
    "                filtered_tokens += [filtered_token.lower()]\n",
    "            else:\n",
    "                filtered_tokens += [filtered_token]\n",
    "\n",
    "    return filtered_tokens, isEnglishReadme\n",
    "\n",
    "\n",
    "def convert_markdown(text):\n",
    "    rv = ''.join(text.findAll(text=True))\n",
    "    return rv\n",
    "\n",
    "\n",
    "def md2html(md):\n",
    "    return BeautifulSoup(markdown(md))\n",
    "\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        #         print(s)\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]\n",
    "\n",
    "\n",
    "def get_readme_metrics(project_name, readme_md):\n",
    "    if isinstance(project_name, float) and math.isnan(project_name):\n",
    "        project_name = \"\"\n",
    "\n",
    "    headers_pair = find_all_headers(readme_md)\n",
    "\n",
    "    headers = [t for n, t in headers_pair]\n",
    "\n",
    "    codes_pair = find_all_codes(readme_md)\n",
    "    codes = [t for n, t in codes_pair]\n",
    "\n",
    "    blocks = find_all_blocks(readme_md)\n",
    "\n",
    "    images = find_all_images(readme_md)\n",
    "\n",
    "    urls = find_all_urls(readme_md)\n",
    "\n",
    "    filtered_readme = list(map(lambda x: filter_readme(convert_markdown(BeautifulSoup(x))), blocks))\n",
    "    # first tokenlized readme blocks and booleans indicating if each block is pure English\n",
    "    tokenlized_blocks, isEnglish = list(zip(*filtered_readme))\n",
    "\n",
    "    isEnglish = list(isEnglish)\n",
    "    tokenlized_blocks = list(tokenlized_blocks)\n",
    "\n",
    "    blocks_token_counts = list(map(len, tokenlized_blocks))[-len(headers):]\n",
    "    blocks_token_counts_np = np.array(blocks_token_counts)\n",
    "\n",
    "    if blocks_token_counts_np.size == 0:\n",
    "        blocks_token_counts_np = np.array([0])\n",
    "\n",
    "    blocks_token_counts_min = np.min(blocks_token_counts_np)\n",
    "    blocks_token_counts_max = np.max(blocks_token_counts_np)\n",
    "    blocks_token_counts_mean = np.mean(blocks_token_counts_np)\n",
    "    blocks_token_counts_median = np.median(blocks_token_counts_np)\n",
    "\n",
    "    #   clean_readme, original_readme = preprocess_readme(readme_md)\n",
    "\n",
    "    #   clean_readme = clean_readme.lower()\n",
    "\n",
    "    #   readme_tokens = filter_readme(clean_readme)\n",
    "\n",
    "    #   readme_tokens = remove_special_chars(readme_tokens)\n",
    "\n",
    "    aligned_headers = headers.copy()\n",
    "    aligned_headers.insert(0, \"\")\n",
    "\n",
    "    # merge blocked with the headers for checking if entire readme is English only\n",
    "    isEnglish = isEnglish + [filter_readme(h)[1] for h in aligned_headers]\n",
    "    isEnglish = 1 if all(isEnglish) else 0\n",
    "\n",
    "    reconstructed_readme_tokens = [filter_readme(h)[0] + c for h, c in zip(aligned_headers, tokenlized_blocks)]\n",
    "\n",
    "    reconstructed_readme_tokens = reduce(lambda x, y: x + y, reconstructed_readme_tokens)\n",
    "\n",
    "    readme_tokens = reconstructed_readme_tokens\n",
    "\n",
    "    readme_body_tokens = reduce(lambda x, y: x + y, tokenlized_blocks)\n",
    "\n",
    "    # header only keyword search\n",
    "    isNameInReadmeHeaders = list_contains(headers,\n",
    "                                          project_name.lower())  # or header_contain_project_name(headers, project_name.lower())\n",
    "\n",
    "    isNameHeaderNotEmpty = 0\n",
    "    if isNameInReadmeHeaders:\n",
    "        name_idx = list_kw_index(aligned_headers, project_name.lower())\n",
    "        #     print(name_idx)\n",
    "\n",
    "        if name_idx == -1:\n",
    "            raise Exception('Unable to find the index of project name header!')\n",
    "\n",
    "        #     print(tokenlized_blocks)\n",
    "        isNameHeaderNotEmpty = 0 if len(tokenlized_blocks[name_idx]) == 0 else 1\n",
    "\n",
    "    isDescriptionKWInReadmeHeaders = list_contains(headers, 'describe') or list_contains(headers,\n",
    "                                                                                         'description') or list_contains(\n",
    "        headers, 'summary') or list_contains(headers, 'overview') or list_contains(headers,\n",
    "                                                                                   'introduction') or list_contains(\n",
    "        headers, 'about') or list_contains(headers, 'introduce') or list_contain_kw_direct(headers, 'what is')\n",
    "    isContentKWInReadmeHeaders = list_contains(headers, 'content')\n",
    "    isInstallationKWInReadmeHeaders = list_contains(headers, 'install') or list_contains(headers,\n",
    "                                                                                         'build') or list_contains(\n",
    "        headers, 'setup') or list_contains(headers, 'download') or list_contains(headers, 'compile')\n",
    "    #   isUsageKWInReadmeHeaders = list_contains(headers, 'use') or list_contains(headers, 'usage') or list_contains(headers, 'customize') or list_contains(headers, 'quickstart') or list_contains(headers, 'run') or list_contains(headers, 'start') or list_contain_kw_direct(headers, 'getting started') or list_contain_kw_direct(headers, 'quick guide')\n",
    "    isUsageKWInReadmeHeaders = list_contains(headers, 'use') or list_contains(headers, 'usage') or list_contains(\n",
    "        headers, 'quickstart') or list_contains(headers, 'run') or list_contains(headers, 'start')\n",
    "\n",
    "    isContributingKWInReadmeHeaders = list_contains(headers, 'contribute')\n",
    "    isCreditsKWInReadmeHeaders = list_contains(headers, 'credit') or list_contains(headers, 'acknowledge')\n",
    "    isLicenseKWInReadmeHeaders = list_contains(headers, 'license') or list_contains(headers,\n",
    "                                                                                    'licence') or list_contains(headers,\n",
    "                                                                                                                'copyright')\n",
    "    isTestKWInReadmeHeaders = list_contains(headers, 'test')\n",
    "\n",
    "    isDocumentKWInReadmeHeaders = list_contains(headers, 'document') or list_contains(headers, 'docs')\n",
    "\n",
    "    isArchiveKWInReadmeHeaders = list_contains(headers, 'archive')\n",
    "\n",
    "    isExampleKWInReadmeHeaders = list_contains(headers, 'example') or list_contains(headers, 'demo') or list_contains(\n",
    "        headers, 'sample')\n",
    "\n",
    "    isAuthorKWInReadmeHeaders = list_contains_exact(headers, 'author') or list_contains_exact(headers,\n",
    "                                                                                              'authors') or list_contain_kw_direct(\n",
    "        headers, 'developed by') or list_contain_kw_direct(headers, 'created by')\n",
    "\n",
    "    isTroubleshootKWInReadmeHeaders = list_contains(headers, 'troubleshoot')\n",
    "\n",
    "    isScreenshotKWInReadmeHeaders = list_contains(headers, 'screenshot')\n",
    "\n",
    "    isDeprecateKWInReadmeHeaders = list_contains(headers, 'deprecate') or list_contains(headers, 'retire')\n",
    "\n",
    "    isMovedKWInReadmeHeaders = list_contain_kw_direct(headers, 'moved')\n",
    "\n",
    "    isFeatureKWInReadmeHeaders = list_contains(headers, 'feature')\n",
    "\n",
    "    isConfigureKWInReadmeHeaders = list_contains(headers, 'configure')\n",
    "\n",
    "    isDependencyKWInReadmeHeaders = list_contains(headers, 'dependency') or list_contains(headers, 'requirement')\n",
    "\n",
    "    isReferenceKWInReadmeHeaders = list_contains(headers, 'reference')\n",
    "\n",
    "    isReleaseKWInReadmeHeaders = list_contains(headers, 'release')\n",
    "\n",
    "    isChangelogInReadmeHeaders = list_contains(headers, 'changelog')\n",
    "\n",
    "    isQuestionInReadmeHeaders = list_contains(headers, 'question')\n",
    "\n",
    "    isIssueInReadmeHeaders = list_contains(headers, 'issue')\n",
    "\n",
    "    isNoteInReadmeHeaders = list_contains(headers, 'note') or list_contains(headers, 'remark')\n",
    "\n",
    "    # body only keyword search\n",
    "    isDeprecateKWInReadmeBody = list_contains(readme_body_tokens, 'deprecate') or list_contains(readme_body_tokens,\n",
    "                                                                                                'retire')\n",
    "\n",
    "    isMovedKWInReadmeBody = list_contain_kw_direct(readme_body_tokens, 'moved')\n",
    "\n",
    "    isLicenseKWInReadmeBody = list_contains(readme_body_tokens, 'license') or list_contains(readme_body_tokens,\n",
    "                                                                                            'licence') or list_contains(\n",
    "        readme_body_tokens, 'copyright')\n",
    "\n",
    "    isAuthorKWInReadmeBody = list_contains_exact(readme_body_tokens, 'author') or list_contains_exact(\n",
    "        readme_body_tokens, 'authors') or list_contain_kw_direct(readme_body_tokens,\n",
    "                                                                 'developed by') or list_contain_kw_direct(\n",
    "        readme_body_tokens, 'created by')\n",
    "\n",
    "    metrics = {\n",
    "        #       'reconstructed_readme_tokens': len(reconstructed_readme_tokens),\n",
    "        'isEnglishReadme': isEnglish,\n",
    "        'readme_header_count': len(headers),\n",
    "        'readme_code_block_count': len(codes),\n",
    "        'readme_image_count': len(images),\n",
    "        'readme_url_count': len(urls),\n",
    "        #       'blocks_token_counts_min': blocks_token_counts_min,\n",
    "        #       'blocks_token_counts_max': blocks_token_counts_max,\n",
    "        #       'blocks_token_counts_mean': blocks_token_counts_mean,\n",
    "        #       'blocks_token_counts_median': blocks_token_counts_median,\n",
    "        'project_name_header_kw': isNameInReadmeHeaders,\n",
    "        'project_name_header_non_empty': isNameHeaderNotEmpty,\n",
    "        'description_header_kw': isDescriptionKWInReadmeHeaders,\n",
    "        'content_header_kw': isContentKWInReadmeHeaders,\n",
    "        'install_header_kw': isInstallationKWInReadmeHeaders,\n",
    "        'usage_header_kw': isUsageKWInReadmeHeaders,\n",
    "        'contribut_header_kw': isContributingKWInReadmeHeaders,\n",
    "        'credit_header_kw': isCreditsKWInReadmeHeaders,\n",
    "        'license_header_kw': isLicenseKWInReadmeHeaders,\n",
    "        'test_header_kw': isTestKWInReadmeHeaders,\n",
    "        'document_header_kw': isDocumentKWInReadmeHeaders,\n",
    "        'archive_header_kw': isArchiveKWInReadmeHeaders,\n",
    "        'example_header_kw': isExampleKWInReadmeHeaders,\n",
    "        'author_header_kw': isAuthorKWInReadmeHeaders,\n",
    "        'troubleshoot_header_kw': isTroubleshootKWInReadmeHeaders,\n",
    "        'screenshot_header_kw': isScreenshotKWInReadmeHeaders,\n",
    "        'deprecate_header_kw': isDeprecateKWInReadmeHeaders,\n",
    "        'moved_header_kw': isMovedKWInReadmeHeaders,\n",
    "        'feature_header_kw': isFeatureKWInReadmeHeaders,\n",
    "        'configure_header_kw': isConfigureKWInReadmeHeaders,\n",
    "        'dependency_header_kw': isDependencyKWInReadmeHeaders,\n",
    "        'reference_header_kw': isReferenceKWInReadmeHeaders,\n",
    "        'release_header_kw': isReleaseKWInReadmeHeaders,\n",
    "        'changelog_header_kw': isChangelogInReadmeHeaders,\n",
    "        'question_header_kw': isQuestionInReadmeHeaders,\n",
    "        'issue_header_kw': isIssueInReadmeHeaders,\n",
    "        'note_header_kw': isNoteInReadmeHeaders,\n",
    "\n",
    "        'license_body_kw': isLicenseKWInReadmeBody,\n",
    "        'author_body_kw': isAuthorKWInReadmeBody,\n",
    "\n",
    "        'deprecate_body_kw': isDeprecateKWInReadmeBody,\n",
    "        'moved_body_kw': isMovedKWInReadmeBody,\n",
    "\n",
    "        #       'readme_tokens':readme_tokens,\n",
    "        'readme_tokens_count': len(readme_tokens)\n",
    "    }\n",
    "\n",
    "    #   return pd.DataFrame(metrics, index=['thisisaindex']).transpose().thisisaindex\n",
    "    return pd.Series(list(metrics.values()), index=list(metrics.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_metrics = df_readme.progress_apply(lambda x: get_readme_metrics(x['name'], x.readme), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5a567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
